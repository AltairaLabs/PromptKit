package turnexecutors

import (
	"context"
	"errors"
	"fmt"
	"strings"

	"github.com/AltairaLabs/PromptKit/runtime/pipeline"
	"github.com/AltairaLabs/PromptKit/runtime/pipeline/middleware"
	"github.com/AltairaLabs/PromptKit/runtime/providers"
	"github.com/AltairaLabs/PromptKit/runtime/statestore"
	"github.com/AltairaLabs/PromptKit/runtime/types"
	"github.com/AltairaLabs/PromptKit/runtime/validators"
	arenamiddleware "github.com/AltairaLabs/PromptKit/tools/arena/middleware"
	"github.com/AltairaLabs/PromptKit/tools/arena/selfplay"
)

// SelfPlayExecutor executes turns where the user message is generated by an LLM
type SelfPlayExecutor struct {
	pipelineExecutor *PipelineExecutor
	contentProvider  selfplay.Provider
}

// NewSelfPlayExecutor creates a new executor for self-play turns
func NewSelfPlayExecutor(pipelineExecutor *PipelineExecutor, contentProvider selfplay.Provider) *SelfPlayExecutor {
	return &SelfPlayExecutor{
		pipelineExecutor: pipelineExecutor,
		contentProvider:  contentProvider,
	}
}

// ExecuteTurn executes a self-play turn (LLM-generated user message + AI response)
func (e *SelfPlayExecutor) ExecuteTurn(ctx context.Context, req TurnRequest) error {
	// Load history from StateStore if configured
	history, err := e.loadHistory(ctx, req)
	if err != nil {
		return err
	}

	// Generate user message using LLM
	userMessage, err := e.generateUserMessage(ctx, req, history)
	if err != nil {
		return err
	}

	// Execute AI response through the pipeline
	return e.pipelineExecutor.Execute(ctx, req, userMessage)
}

// loadHistory loads conversation history from StateStore
func (e *SelfPlayExecutor) loadHistory(ctx context.Context, req TurnRequest) ([]types.Message, error) {
	if req.StateStoreConfig == nil || req.ConversationID == "" {
		return nil, nil
	}

	store, ok := req.StateStoreConfig.Store.(statestore.Store)
	if !ok {
		return nil, nil
	}

	state, err := store.Load(ctx, req.ConversationID)
	if err != nil && !errors.Is(err, statestore.ErrNotFound) {
		return nil, fmt.Errorf("failed to load history from StateStore: %w", err)
	}

	if state != nil && len(state.Messages) > 0 {
		return state.Messages, nil
	}

	return nil, nil
}

// generateUserMessage generates a user message using the content provider
func (e *SelfPlayExecutor) generateUserMessage(
	ctx context.Context,
	req TurnRequest,
	history []types.Message,
) (types.Message, error) {
	filteredHistory := filterOutToolMessages(history)

	contentGen, err := e.contentProvider.GetContentGenerator(req.SelfPlayRole, req.SelfPlayPersona)
	if err != nil {
		return types.Message{}, fmt.Errorf("failed to get content generator: %w", err)
	}

	execResult, err := contentGen.NextUserTurn(ctx, filteredHistory, req.Scenario.ID)
	if err != nil {
		return types.Message{}, fmt.Errorf("failed to generate user turn: %w", err)
	}

	if execResult.Response == nil || execResult.Response.Content == "" {
		return types.Message{}, fmt.Errorf("no response content generated")
	}

	return e.buildUserMessageFromResult(req, execResult), nil
}

// buildUserMessageFromResult constructs a user message from execution result
func (e *SelfPlayExecutor) buildUserMessageFromResult(
	req TurnRequest,
	execResult *pipeline.ExecutionResult,
) types.Message {
	selfPlayMeta := e.buildSelfPlayMetadata(req, execResult)

	var latencyMs int64
	if execResult.Trace.CompletedAt != nil {
		latencyMs = execResult.Trace.CompletedAt.Sub(execResult.Trace.StartedAt).Milliseconds()
	}

	return types.Message{
		Role:      "user",
		Content:   execResult.Response.Content,
		CostInfo:  &execResult.CostInfo,
		LatencyMs: latencyMs,
		Meta: map[string]interface{}{
			"raw_response": selfPlayMeta,
		},
	}
}

// buildSelfPlayMetadata creates metadata for self-play execution
func (e *SelfPlayExecutor) buildSelfPlayMetadata(
	req TurnRequest,
	execResult *pipeline.ExecutionResult,
) map[string]interface{} {
	meta := map[string]interface{}{
		"role":                req.SelfPlayRole,
		"self_play_execution": true,
		"trace":               execResult.Trace,
	}

	if execResult.Metadata != nil {
		for k, v := range execResult.Metadata {
			meta[k] = v
		}
	}

	return meta
}

// ExecuteTurnStream executes a self-play turn with streaming
func (e *SelfPlayExecutor) ExecuteTurnStream(
	ctx context.Context,
	req TurnRequest,
) (<-chan MessageStreamChunk, error) {
	outChan := make(chan MessageStreamChunk)

	go func() {
		defer close(outChan)

		// Load history from StateStore if configured
		history, err := e.loadHistoryForStream(ctx, req, outChan)
		if err != nil {
			return // Error already sent to channel
		}

		// Generate user message using LLM
		userMessage, err := e.generateUserMessageForStream(ctx, req, history, outChan)
		if err != nil {
			return // Error already sent to channel
		}

		// Handle non-streaming providers
		if e.handleNonStreamingProvider(ctx, req, userMessage, outChan) {
			return
		}

		// Execute streaming pipeline
		e.executeStreamingPipeline(ctx, req, userMessage, outChan)
	}()

	return outChan, nil
}

// loadHistoryForStream loads conversation history from StateStore
func (e *SelfPlayExecutor) loadHistoryForStream(
	ctx context.Context,
	req TurnRequest,
	outChan chan<- MessageStreamChunk,
) ([]types.Message, error) {
	if req.StateStoreConfig == nil || req.ConversationID == "" {
		return nil, nil
	}

	store, ok := req.StateStoreConfig.Store.(statestore.Store)
	if !ok {
		return nil, nil
	}

	state, err := store.Load(ctx, req.ConversationID)
	if err != nil && !errors.Is(err, statestore.ErrNotFound) {
		outChan <- MessageStreamChunk{
			Error: fmt.Errorf("failed to load history from StateStore: %w", err),
		}
		return nil, err
	}

	if state != nil && len(state.Messages) > 0 {
		return state.Messages, nil
	}

	return nil, nil
}

// generateUserMessageForStream generates the user message for self-play
func (e *SelfPlayExecutor) generateUserMessageForStream(
	ctx context.Context,
	req TurnRequest,
	history []types.Message,
	outChan chan<- MessageStreamChunk,
) (types.Message, error) {
	// Tool role messages are not valid input for LLM chat APIs; drop them before generation.
	filteredHistory := filterOutToolMessages(history)

	contentGen, err := e.contentProvider.GetContentGenerator(req.SelfPlayRole, req.SelfPlayPersona)
	if err != nil {
		outChan <- MessageStreamChunk{Error: fmt.Errorf("failed to get content generator: %w", err)}
		return types.Message{}, err
	}

	execResult, err := contentGen.NextUserTurn(ctx, filteredHistory, req.Scenario.ID)
	if err != nil {
		outChan <- MessageStreamChunk{Error: fmt.Errorf("failed to generate user turn: %w", err)}
		return types.Message{}, err
	}

	if execResult.Response == nil || execResult.Response.Content == "" {
		err := fmt.Errorf("no response content generated")
		outChan <- MessageStreamChunk{Error: err}
		return types.Message{}, err
	}

	return e.buildUserMessage(req, execResult), nil
}

// buildUserMessage constructs a user message from execution result
func (e *SelfPlayExecutor) buildUserMessage(
	req TurnRequest,
	execResult *pipeline.ExecutionResult,
) types.Message {
	userMessage := types.Message{
		Role:     "user",
		Content:  execResult.Response.Content,
		CostInfo: &execResult.CostInfo,
	}

	if execResult.Trace.CompletedAt != nil {
		userMessage.LatencyMs = execResult.Trace.CompletedAt.Sub(execResult.Trace.StartedAt).Milliseconds()
	}

	selfPlayMeta := map[string]interface{}{
		"role":                req.SelfPlayRole,
		"self_play_execution": true,
		"trace":               execResult.Trace,
	}

	if execResult.Metadata != nil {
		for k, v := range execResult.Metadata {
			selfPlayMeta[k] = v
		}
	}

	userMessage.Meta = map[string]interface{}{
		"raw_response": selfPlayMeta,
	}

	return userMessage
}

// filterOutToolMessages removes tool role messages from history to avoid invalid provider payloads.
func filterOutToolMessages(messages []types.Message) []types.Message {
	if len(messages) == 0 {
		return messages
	}
	filtered := make([]types.Message, 0, len(messages))
	for i := range messages {
		if strings.EqualFold(messages[i].Role, "tool") {
			continue
		}
		filtered = append(filtered, messages[i])
	}
	return filtered
}

// handleNonStreamingProvider handles providers that don't support streaming
// Returns true if handled (caller should return)
func (e *SelfPlayExecutor) handleNonStreamingProvider(
	ctx context.Context,
	req TurnRequest,
	userMessage types.Message,
	outChan chan<- MessageStreamChunk,
) bool {
	if req.Provider.SupportsStreaming() {
		return false
	}

	messages := []types.Message{userMessage}
	err := e.pipelineExecutor.Execute(ctx, req, userMessage)
	if err != nil {
		outChan <- MessageStreamChunk{Messages: messages, Error: err}
		return true
	}

	finishReason := "stop"
	outChan <- MessageStreamChunk{
		Messages:     []types.Message{},
		FinishReason: &finishReason,
	}
	return true
}

// executeStreamingPipeline builds and executes the streaming pipeline
func (e *SelfPlayExecutor) executeStreamingPipeline(
	ctx context.Context,
	req TurnRequest,
	userMessage types.Message,
	outChan chan<- MessageStreamChunk,
) {
	messages := []types.Message{userMessage}

	// Build and execute pipeline
	middlewares := e.buildStreamingMiddlewares(req)
	pl := pipeline.NewPipeline(middlewares...)

	streamChan, err := pl.ExecuteStream(ctx, userMessage.Role, userMessage.Content)
	if err != nil {
		outChan <- MessageStreamChunk{Messages: messages, Error: err}
		return
	}

	// Forward stream chunks
	e.forwardStreamChunks(streamChan, messages, outChan)
}

// stripToolMessagesMiddleware removes tool role messages before calling the self-play provider.
func stripToolMessagesMiddleware() pipeline.Middleware {
	return &stripToolMessages{}
}

type stripToolMessages struct{}

// Process removes tool-role messages before passing execution to the provider.
func (m *stripToolMessages) Process(execCtx *pipeline.ExecutionContext, next func() error) error {
	if len(execCtx.Messages) == 0 {
		return next()
	}
	filtered := make([]types.Message, 0, len(execCtx.Messages))
	for i := range execCtx.Messages {
		if strings.EqualFold(execCtx.Messages[i].Role, "tool") {
			continue
		}
		filtered = append(filtered, execCtx.Messages[i])
	}
	execCtx.Messages = filtered
	return next()
}

// StreamChunk is a no-op to satisfy the middleware interface.
func (m *stripToolMessages) StreamChunk(execCtx *pipeline.ExecutionContext, chunk *providers.StreamChunk) error {
	return nil
}

// buildStreamingMiddlewares constructs the middleware chain for streaming
func (e *SelfPlayExecutor) buildStreamingMiddlewares(req TurnRequest) []pipeline.Middleware {
	baseVariables := buildBaseVariables(req.Region)
	mergedVars := map[string]string{}
	for k, v := range baseVariables {
		mergedVars[k] = v
	}
	for k, v := range req.PromptVars {
		mergedVars[k] = v
	}

	providerConfig := &middleware.ProviderMiddlewareConfig{
		MaxTokens:   req.MaxTokens,
		Temperature: float32(req.Temperature),
		Seed:        req.Seed,
	}

	var middlewares []pipeline.Middleware

	// StateStore Load middleware
	if req.StateStoreConfig != nil && req.ConversationID != "" {
		storeConfig := &pipeline.StateStoreConfig{
			Store:          req.StateStoreConfig.Store,
			ConversationID: req.ConversationID,
			UserID:         req.StateStoreConfig.UserID,
			Metadata:       req.StateStoreConfig.Metadata,
		}
		middlewares = append(
			middlewares,
			middleware.StateStoreLoadMiddleware(storeConfig),
			// Compute authoritative turn indices right after loading state
			arenamiddleware.TurnIndexMiddleware(),
		)
	}

	// Variable injection
	extraMiddlewares := []pipeline.Middleware{
		&variableInjectionMiddleware{variables: mergedVars},
	}
	if len(req.Metadata) > 0 {
		extraMiddlewares = append(extraMiddlewares, &metadataInjectionMiddleware{metadata: req.Metadata})
	}
	middlewares = append(middlewares, extraMiddlewares...)
	// Prompt and template middleware
	middlewares = append(middlewares,
		middleware.PromptAssemblyMiddleware(req.PromptRegistry, req.TaskType, mergedVars),
		middleware.TemplateMiddleware(),
		stripToolMessagesMiddleware(), // Do not send tool messages to self-play user LLMs
	)

	// Mock scenario context for mock providers (pre-provider)
	if isMockProvider(req.Provider) {
		middlewares = append(middlewares, arenamiddleware.MockScenarioContextMiddleware(req.Scenario))
	}

	// Provider + Dynamic validator middleware with suppression
	middlewares = append(
		middlewares,
		middleware.ProviderMiddleware(req.Provider, nil, nil, providerConfig),
		middleware.DynamicValidatorMiddlewareWithSuppression(validators.DefaultRegistry, true),
	)

	// StateStore Save middleware
	if req.StateStoreConfig != nil && req.ConversationID != "" {
		storeConfig := &pipeline.StateStoreConfig{
			Store:          req.StateStoreConfig.Store,
			ConversationID: req.ConversationID,
			UserID:         req.StateStoreConfig.UserID,
			Metadata:       req.StateStoreConfig.Metadata,
		}
		middlewares = append(middlewares, middleware.StateStoreSaveMiddleware(storeConfig))
	}

	return middlewares
}

// forwardStreamChunks forwards stream chunks from pipeline to output channel
func (e *SelfPlayExecutor) forwardStreamChunks(
	streamChan <-chan providers.StreamChunk,
	messages []types.Message,
	outChan chan<- MessageStreamChunk,
) {
	assistantIndex := 1
	var assistantMsg types.Message
	assistantMsg.Role = "assistant"

	for chunk := range streamChan {
		if chunk.Error != nil {
			outChan <- MessageStreamChunk{Messages: messages, Error: chunk.Error}
			return
		}

		if chunk.FinalResult != nil {
			break
		}

		assistantMsg = e.updateAssistantMessage(assistantMsg, chunk)
		messages = e.updateMessagesList(messages, assistantMsg, assistantIndex)

		outChan <- MessageStreamChunk{
			Messages:     messages,
			Delta:        chunk.Delta,
			MessageIndex: assistantIndex,
			TokenCount:   chunk.TokenCount,
			FinishReason: chunk.FinishReason,
		}

		if chunk.FinishReason != nil {
			break
		}
	}
}

// updateAssistantMessage updates assistant message with chunk data
func (e *SelfPlayExecutor) updateAssistantMessage(
	msg types.Message,
	chunk providers.StreamChunk,
) types.Message {
	msg.Content = chunk.Content

	if len(chunk.ToolCalls) > 0 {
		msg.ToolCalls = make([]types.MessageToolCall, len(chunk.ToolCalls))
		for i, tc := range chunk.ToolCalls {
			msg.ToolCalls[i] = types.MessageToolCall{
				ID:   tc.ID,
				Name: tc.Name,
				Args: tc.Args,
			}
		}
	}

	return msg
}

// updateMessagesList updates the messages list with current assistant message
func (e *SelfPlayExecutor) updateMessagesList(
	messages []types.Message,
	assistantMsg types.Message,
	assistantIndex int,
) []types.Message {
	if len(messages) == assistantIndex {
		return append(messages, assistantMsg)
	}
	messages[assistantIndex] = assistantMsg
	return messages
}
