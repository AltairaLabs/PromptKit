apiVersion: promptkit.altairalabs.ai/v1alpha1
kind: Arena
metadata:
  name: eval-test
spec:
  providers:
    - file: providers/replay.provider.yaml
    - file: providers/gpt-4o-judge.provider.yaml

  judges:
    - name: gpt-4o-judge
      provider: gpt-4o-judge

  evals:
    - file: evals/basic-eval.eval.yaml

  defaults:
    temperature: 0.7
    max_tokens: 1000
    concurrency: 1
    output:
      dir: out
      formats:
        - json
        - html
      html:
        file: document-report.html
      
