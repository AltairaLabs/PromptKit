apiVersion: promptkit.altairalabs.ai/v1alpha1
kind: Provider
metadata:
  name: ollama-k8s
  annotations:
    description: "Llama 3.2 1B model running via Ollama on Kubernetes"
spec:
  id: "ollama-k8s"
  type: ollama
  model: llama3.2:1b
  # Point to Ollama service running in Kubernetes (via port-forward or ingress)
  # For port-forward: kubectl port-forward -n ollama-system svc/ollama 11434:11434
  base_url: "http://localhost:11434"
  additional_config:
    # Keep the model loaded in memory for 5 minutes between requests
    keep_alive: "5m"
  defaults:
    temperature: 0.7
    max_tokens: 1024
    top_p: 0.9
