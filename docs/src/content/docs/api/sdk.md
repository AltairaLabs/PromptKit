---
title: SDK API Reference
description: Complete API reference for the PromptKit Go SDK
sidebar:
  order: 1
---
<!-- Code generated by gomarkdoc. DO NOT EDIT -->

# sdk

```go
import "github.com/AltairaLabs/PromptKit/sdk"
```

Package sdk provides a simple API for LLM conversations using PromptPack files.

SDK v2 is a pack\-first SDK where everything starts from a .pack.json file. The pack contains prompts, variables, tools, validators, and model configuration. The SDK loads the pack and provides a minimal API to interact with LLMs.

### Quick Start

The simplest possible usage is just 5 lines:

```
conv, err := sdk.Open("./assistant.pack.json", "chat")
if err != nil {
    log.Fatal(err)
}
defer conv.Close()

resp, _ := conv.Send(ctx, "Hello!")
fmt.Println(resp.Text())
```

### Core Concepts

Opening a Conversation:

Use [Open](<#Open>) to load a pack file and create a conversation for a specific prompt:

```
// Minimal - provider auto-detected from environment
conv, _ := sdk.Open("./demo.pack.json", "troubleshooting")

// With options - override model, provider, etc.
conv, _ := sdk.Open("./demo.pack.json", "troubleshooting",
    sdk.WithModel("gpt-4o"),
    sdk.WithAPIKey(os.Getenv("MY_OPENAI_KEY")),
)
```

Variables:

Variables defined in the pack are populated at runtime:

```
conv.SetVar("customer_id", "acme-corp")
conv.SetVars(map[string]any{
    "customer_name": "ACME Corporation",
    "tier": "premium",
})
```

Tools:

Tools defined in the pack just need implementation handlers:

```
conv.OnTool("list_devices", func(args map[string]any) (any, error) {
    return myAPI.ListDevices(args["customer_id"].(string))
})
```

Streaming:

Stream responses chunk by chunk:

```
for chunk := range conv.Stream(ctx, "Tell me a story") {
    fmt.Print(chunk.Text)
}
```

### Design Principles

1. Pack is the Source of Truth \- The .pack.json file defines prompts, tools, validators, and pipeline configuration. The SDK configures itself automatically.
2. Convention Over Configuration \- API keys from environment, provider auto\-detection, model defaults from pack. Override only when needed.
3. Progressive Disclosure \- Simple things are simple, advanced features available but not required.
4. Same Runtime, Same Behavior \- SDK v2 uses the same runtime pipeline as Arena. Pack\-defined behaviors work identically.
5. Thin Wrapper \- No type duplication. Core types like Message, ContentPart, CostInfo come directly from runtime/types.

### Package Structure

The SDK is organized into sub\-packages for specific functionality:

- sdk \(this package\): Entry point, [Open](<#Open>), [Conversation](<#Conversation>), [Response](<#Response>)
- sdk/tools: Typed tool handlers, HITL support
- sdk/stream: Streaming response handling
- sdk/message: Multimodal message building
- sdk/hooks: Event subscription and lifecycle hooks
- sdk/validation: Validator registration and error handling

Most users only need to import the root sdk package.

### Runtime Types

The SDK uses runtime types directly \- no duplication:

```
import "github.com/AltairaLabs/PromptKit/runtime/types"

msg := &types.Message{Role: "user"}
msg.AddTextPart("Hello")
```

Key runtime types: \[types.Message\], \[types.ContentPart\], \[types.MediaContent\], \[types.CostInfo\], \[types.ValidationResult\].

### Schema Reference

All pack examples conform to the PromptPack Specification v1.1.0: https://github.com/AltairaLabs/promptpack-spec/blob/main/schema/promptpack.schema.json

## Index

- [Variables](<#variables>)
- [type ChunkType](<#ChunkType>)
  - [func \(t ChunkType\) String\(\) string](<#ChunkType.String>)
- [type Conversation](<#Conversation>)
  - [func Open\(packPath, promptName string, opts ...Option\) \(\*Conversation, error\)](<#Open>)
  - [func OpenDuplex\(packPath, promptName string, opts ...Option\) \(\*Conversation, error\)](<#OpenDuplex>)
  - [func Resume\(conversationID, packPath, promptName string, opts ...Option\) \(\*Conversation, error\)](<#Resume>)
  - [func \(c \*Conversation\) CheckPending\(name string, args map\[string\]any\) \(\*sdktools.PendingToolCall, bool\)](<#Conversation.CheckPending>)
  - [func \(c \*Conversation\) Clear\(\) error](<#Conversation.Clear>)
  - [func \(c \*Conversation\) Close\(\) error](<#Conversation.Close>)
  - [func \(c \*Conversation\) Continue\(ctx context.Context\) \(\*Response, error\)](<#Conversation.Continue>)
  - [func \(c \*Conversation\) Done\(\) \(\<\-chan struct\{\}, error\)](<#Conversation.Done>)
  - [func \(c \*Conversation\) EventBus\(\) \*events.EventBus](<#Conversation.EventBus>)
  - [func \(c \*Conversation\) Fork\(\) \*Conversation](<#Conversation.Fork>)
  - [func \(c \*Conversation\) GetVar\(name string\) \(string, bool\)](<#Conversation.GetVar>)
  - [func \(c \*Conversation\) ID\(\) string](<#Conversation.ID>)
  - [func \(c \*Conversation\) Messages\(ctx context.Context\) \[\]types.Message](<#Conversation.Messages>)
  - [func \(c \*Conversation\) OnTool\(name string, handler ToolHandler\)](<#Conversation.OnTool>)
  - [func \(c \*Conversation\) OnToolAsync\(name string, checkFunc func\(args map\[string\]any\) sdktools.PendingResult, execFunc ToolHandler\)](<#Conversation.OnToolAsync>)
  - [func \(c \*Conversation\) OnToolCtx\(name string, handler ToolHandlerCtx\)](<#Conversation.OnToolCtx>)
  - [func \(c \*Conversation\) OnToolExecutor\(name string, executor tools.Executor\)](<#Conversation.OnToolExecutor>)
  - [func \(c \*Conversation\) OnToolHTTP\(name string, config \*sdktools.HTTPToolConfig\)](<#Conversation.OnToolHTTP>)
  - [func \(c \*Conversation\) OnTools\(handlers map\[string\]ToolHandler\)](<#Conversation.OnTools>)
  - [func \(c \*Conversation\) PendingTools\(\) \[\]\*sdktools.PendingToolCall](<#Conversation.PendingTools>)
  - [func \(c \*Conversation\) RejectTool\(id, reason string\) \(\*sdktools.ToolResolution, error\)](<#Conversation.RejectTool>)
  - [func \(c \*Conversation\) ResolveTool\(id string\) \(\*sdktools.ToolResolution, error\)](<#Conversation.ResolveTool>)
  - [func \(c \*Conversation\) Response\(\) \(\<\-chan providers.StreamChunk, error\)](<#Conversation.Response>)
  - [func \(c \*Conversation\) Send\(ctx context.Context, message any, opts ...SendOption\) \(\*Response, error\)](<#Conversation.Send>)
  - [func \(c \*Conversation\) SendChunk\(ctx context.Context, chunk \*providers.StreamChunk\) error](<#Conversation.SendChunk>)
  - [func \(c \*Conversation\) SendText\(ctx context.Context, text string\) error](<#Conversation.SendText>)
  - [func \(c \*Conversation\) SessionError\(\) error](<#Conversation.SessionError>)
  - [func \(c \*Conversation\) SetVar\(name, value string\)](<#Conversation.SetVar>)
  - [func \(c \*Conversation\) SetVars\(vars map\[string\]any\)](<#Conversation.SetVars>)
  - [func \(c \*Conversation\) SetVarsFromEnv\(prefix string\)](<#Conversation.SetVarsFromEnv>)
  - [func \(c \*Conversation\) Stream\(ctx context.Context, message any, opts ...SendOption\) \<\-chan StreamChunk](<#Conversation.Stream>)
  - [func \(c \*Conversation\) StreamRaw\(ctx context.Context, message any\) \(\<\-chan streamPkg.Chunk, error\)](<#Conversation.StreamRaw>)
  - [func \(c \*Conversation\) ToolRegistry\(\) \*tools.Registry](<#Conversation.ToolRegistry>)
  - [func \(c \*Conversation\) TriggerStart\(ctx context.Context, message string\) error](<#Conversation.TriggerStart>)
- [type MCPServerBuilder](<#MCPServerBuilder>)
  - [func NewMCPServer\(name, command string, args ...string\) \*MCPServerBuilder](<#NewMCPServer>)
  - [func \(b \*MCPServerBuilder\) Build\(\) mcp.ServerConfig](<#MCPServerBuilder.Build>)
  - [func \(b \*MCPServerBuilder\) WithArgs\(args ...string\) \*MCPServerBuilder](<#MCPServerBuilder.WithArgs>)
  - [func \(b \*MCPServerBuilder\) WithEnv\(key, value string\) \*MCPServerBuilder](<#MCPServerBuilder.WithEnv>)
- [type Option](<#Option>)
  - [func WithAPIKey\(key string\) Option](<#WithAPIKey>)
  - [func WithConversationID\(id string\) Option](<#WithConversationID>)
  - [func WithDisabledValidators\(names ...string\) Option](<#WithDisabledValidators>)
  - [func WithEventBus\(bus \*events.EventBus\) Option](<#WithEventBus>)
  - [func WithMCP\(name, command string, args ...string\) Option](<#WithMCP>)
  - [func WithMCPServer\(builder \*MCPServerBuilder\) Option](<#WithMCPServer>)
  - [func WithModel\(model string\) Option](<#WithModel>)
  - [func WithProvider\(p providers.Provider\) Option](<#WithProvider>)
  - [func WithRelevanceTruncation\(cfg \*RelevanceConfig\) Option](<#WithRelevanceTruncation>)
  - [func WithSkipSchemaValidation\(\) Option](<#WithSkipSchemaValidation>)
  - [func WithStateStore\(store statestore.Store\) Option](<#WithStateStore>)
  - [func WithStreamingConfig\(streamingConfig \*providers.StreamingInputConfig\) Option](<#WithStreamingConfig>)
  - [func WithStrictValidation\(\) Option](<#WithStrictValidation>)
  - [func WithTTS\(service tts.Service\) Option](<#WithTTS>)
  - [func WithTokenBudget\(tokens int\) Option](<#WithTokenBudget>)
  - [func WithToolRegistry\(registry \*tools.Registry\) Option](<#WithToolRegistry>)
  - [func WithTruncation\(strategy string\) Option](<#WithTruncation>)
  - [func WithTurnDetector\(detector audio.TurnDetector\) Option](<#WithTurnDetector>)
  - [func WithVADMode\(sttService stt.Service, ttsService tts.Service, cfg \*VADModeConfig\) Option](<#WithVADMode>)
  - [func WithValidationMode\(mode ValidationMode\) Option](<#WithValidationMode>)
  - [func WithVariableProvider\(p variables.Provider\) Option](<#WithVariableProvider>)
  - [func WithVariables\(vars map\[string\]string\) Option](<#WithVariables>)
- [type PackError](<#PackError>)
  - [func \(e \*PackError\) Error\(\) string](<#PackError.Error>)
  - [func \(e \*PackError\) Unwrap\(\) error](<#PackError.Unwrap>)
- [type PendingTool](<#PendingTool>)
- [type ProviderError](<#ProviderError>)
  - [func \(e \*ProviderError\) Error\(\) string](<#ProviderError.Error>)
  - [func \(e \*ProviderError\) Unwrap\(\) error](<#ProviderError.Unwrap>)
- [type RelevanceConfig](<#RelevanceConfig>)
- [type Response](<#Response>)
  - [func \(r \*Response\) Cost\(\) float64](<#Response.Cost>)
  - [func \(r \*Response\) Duration\(\) time.Duration](<#Response.Duration>)
  - [func \(r \*Response\) HasMedia\(\) bool](<#Response.HasMedia>)
  - [func \(r \*Response\) HasToolCalls\(\) bool](<#Response.HasToolCalls>)
  - [func \(r \*Response\) InputTokens\(\) int](<#Response.InputTokens>)
  - [func \(r \*Response\) Message\(\) \*types.Message](<#Response.Message>)
  - [func \(r \*Response\) OutputTokens\(\) int](<#Response.OutputTokens>)
  - [func \(r \*Response\) Parts\(\) \[\]types.ContentPart](<#Response.Parts>)
  - [func \(r \*Response\) PendingTools\(\) \[\]PendingTool](<#Response.PendingTools>)
  - [func \(r \*Response\) Text\(\) string](<#Response.Text>)
  - [func \(r \*Response\) TokensUsed\(\) int](<#Response.TokensUsed>)
  - [func \(r \*Response\) ToolCalls\(\) \[\]types.MessageToolCall](<#Response.ToolCalls>)
  - [func \(r \*Response\) Validations\(\) \[\]types.ValidationResult](<#Response.Validations>)
- [type SendOption](<#SendOption>)
  - [func WithAudioFile\(path string\) SendOption](<#WithAudioFile>)
  - [func WithFile\(name string, data \[\]byte\) SendOption](<#WithFile>)
  - [func WithImageData\(data \[\]byte, mimeType string, detail ...\*string\) SendOption](<#WithImageData>)
  - [func WithImageFile\(path string, detail ...\*string\) SendOption](<#WithImageFile>)
  - [func WithImageURL\(url string, detail ...\*string\) SendOption](<#WithImageURL>)
- [type SessionMode](<#SessionMode>)
- [type StreamChunk](<#StreamChunk>)
- [type ToolError](<#ToolError>)
  - [func \(e \*ToolError\) Error\(\) string](<#ToolError.Error>)
  - [func \(e \*ToolError\) Unwrap\(\) error](<#ToolError.Unwrap>)
- [type ToolHandler](<#ToolHandler>)
- [type ToolHandlerCtx](<#ToolHandlerCtx>)
- [type VADModeConfig](<#VADModeConfig>)
  - [func DefaultVADModeConfig\(\) \*VADModeConfig](<#DefaultVADModeConfig>)
- [type ValidationError](<#ValidationError>)
  - [func AsValidationError\(err error\) \(\*ValidationError, bool\)](<#AsValidationError>)
  - [func \(e \*ValidationError\) Error\(\) string](<#ValidationError.Error>)
- [type ValidationMode](<#ValidationMode>)


## Variables

<a name="ErrConversationClosed"></a>Sentinel errors for common failure cases.

```go
var (
    // ErrConversationClosed is returned when Send or Stream is called on a closed conversation.
    ErrConversationClosed = errors.New("conversation is closed")

    // ErrConversationNotFound is returned by Resume when the conversation ID doesn't exist.
    ErrConversationNotFound = errors.New("conversation not found")

    // ErrNoStateStore is returned by Resume when no state store is configured.
    ErrNoStateStore = errors.New("no state store configured")

    // ErrPromptNotFound is returned when the specified prompt doesn't exist in the pack.
    ErrPromptNotFound = errors.New("prompt not found in pack")

    // ErrPackNotFound is returned when the pack file doesn't exist.
    ErrPackNotFound = errors.New("pack file not found")

    // ErrProviderNotDetected is returned when no provider could be auto-detected.
    ErrProviderNotDetected = errors.New("could not detect provider: no API keys found in environment")

    // ErrToolNotRegistered is returned when the LLM calls a tool that has no handler.
    ErrToolNotRegistered = errors.New("tool handler not registered")

    // ErrToolNotInPack is returned when trying to register a handler for a tool not in the pack.
    ErrToolNotInPack = errors.New("tool not defined in pack")
)
```

<a name="ChunkType"></a>
## type ChunkType

ChunkType identifies the type of a streaming chunk.

```go
type ChunkType int
```

<a name="ChunkText"></a>

```go
const (
    // ChunkText indicates the chunk contains text content.
    ChunkText ChunkType = iota

    // ChunkToolCall indicates the chunk contains a tool call.
    ChunkToolCall

    // ChunkMedia indicates the chunk contains media content.
    ChunkMedia

    // ChunkDone indicates streaming is complete.
    ChunkDone
)
```

<a name="ChunkType.String"></a>
### func \(ChunkType\) String

```go
func (t ChunkType) String() string
```

String returns the string representation of the chunk type.

<a name="Conversation"></a>
## type Conversation

Conversation represents an active LLM conversation.

A conversation maintains:

- Connection to the LLM provider
- Message history \(context\)
- Variable state for template substitution
- Tool handlers for function calling
- Validation state

Conversations are created via [Open](<#Open>) or [Resume](<#Resume>) and are safe for concurrent use. Each [Open](<#Open>) call creates an independent conversation with isolated state.

Basic usage:

```
conv, _ := sdk.Open("./assistant.pack.json", "chat")
conv.SetVar("user_name", "Alice")

resp, _ := conv.Send(ctx, "Hello!")
fmt.Println(resp.Text())

resp, _ = conv.Send(ctx, "What's my name?")  // Remembers context
fmt.Println(resp.Text())  // "Your name is Alice"
```

```go
type Conversation struct {
    // contains filtered or unexported fields
}
```

<a name="Open"></a>
### func Open

```go
func Open(packPath, promptName string, opts ...Option) (*Conversation, error)
```

Open loads a pack file and creates a new conversation for the specified prompt.

This is the primary entry point for SDK v2. It:

- Loads and parses the pack file
- Auto\-detects the provider from environment \(OPENAI\_API\_KEY, ANTHROPIC\_API\_KEY, etc.\)
- Configures the runtime pipeline based on pack settings
- Creates an isolated conversation with its own state

Basic usage:

```
conv, err := sdk.Open("./assistant.pack.json", "chat")
if err != nil {
    log.Fatal(err)
}
defer conv.Close()

resp, _ := conv.Send(ctx, "Hello!")
fmt.Println(resp.Text())
```

With options:

```
conv, err := sdk.Open("./assistant.pack.json", "chat",
    sdk.WithModel("gpt-4o"),
    sdk.WithAPIKey(os.Getenv("MY_KEY")),
    sdk.WithStateStore(redisStore),
)
```

The packPath can be:

- Absolute path: "/path/to/assistant.pack.json"
- Relative path: "./packs/assistant.pack.json"
- URL: "https://example.com/packs/assistant.pack.json" \(future\)

The promptName must match a prompt ID defined in the pack's "prompts" section.

<a name="OpenDuplex"></a>
### func OpenDuplex

```go
func OpenDuplex(packPath, promptName string, opts ...Option) (*Conversation, error)
```

OpenDuplex loads a pack file and creates a new duplex streaming conversation for the specified prompt.

This creates a conversation in duplex mode for bidirectional streaming interactions. Use this when you need real\-time streaming input/output with the LLM.

Basic usage:

```
conv, err := sdk.OpenDuplex("./assistant.pack.json", "chat")
if err != nil {
    log.Fatal(err)
}
defer conv.Close()

// Send streaming input
go func() {
    conv.SendText(ctx, "Hello, ")
    conv.SendText(ctx, "how are you?")
}()

// Receive streaming output
respCh, _ := conv.Response()
for chunk := range respCh {
    fmt.Print(chunk.Content)
}
```

The provider must support streaming input \(implement providers.StreamInputSupport\). Currently supported providers: Gemini with certain models.

<a name="Resume"></a>
### func Resume

```go
func Resume(conversationID, packPath, promptName string, opts ...Option) (*Conversation, error)
```

Resume loads an existing conversation from state storage.

Use this to continue a conversation that was previously persisted:

```
store := statestore.NewRedisStore("redis://localhost:6379")
conv, err := sdk.Resume("session-123", "./chat.pack.json", "assistant",
    sdk.WithStateStore(store),
)
if errors.Is(err, sdk.ErrConversationNotFound) {
    // Start new conversation
    conv, _ = sdk.Open("./chat.pack.json", "assistant",
        sdk.WithStateStore(store),
        sdk.WithConversationID("session-123"),
    )
}
```

Resume requires a state store to be configured. If no state store is provided, it returns [ErrNoStateStore](<#ErrConversationClosed>).

<a name="Conversation.CheckPending"></a>
### func \(\*Conversation\) CheckPending

```go
func (c *Conversation) CheckPending(name string, args map[string]any) (*sdktools.PendingToolCall, bool)
```

CheckPending checks if a tool call should be pending and creates it if so. Returns \(pending call, should wait\) \- if should wait is true, the tool shouldn't execute yet.

This method is used internally when processing tool calls from the LLM. It can also be useful for testing HITL workflows:

```
pending, shouldWait := conv.CheckPending("risky_tool", args)
if shouldWait {
    // Tool requires approval
}
```

<a name="Conversation.Clear"></a>
### func \(\*Conversation\) Clear

```go
func (c *Conversation) Clear() error
```

Clear removes all messages from the conversation history.

This keeps the system prompt and variables but removes all user/assistant messages. Useful for starting fresh within the same conversation session. In duplex mode, this will close the session first if actively streaming.

<a name="Conversation.Close"></a>
### func \(\*Conversation\) Close

```go
func (c *Conversation) Close() error
```

Close releases resources associated with the conversation.

After Close is called, Send and Stream will return [ErrConversationClosed](<#ErrConversationClosed>). It's safe to call Close multiple times.

<a name="Conversation.Continue"></a>
### func \(\*Conversation\) Continue

```go
func (c *Conversation) Continue(ctx context.Context) (*Response, error)
```

Continue resumes conversation after resolving pending tools.

Call this after approving/rejecting all pending tools to continue the conversation with the tool results:

```
resp, _ := conv.Send(ctx, "Process refund")
for _, pending := range resp.PendingTools() {
    conv.ResolveTool(pending.ID)
}
resp, _ = conv.Continue(ctx) // LLM receives tool results
```

<a name="Conversation.Done"></a>
### func \(\*Conversation\) Done

```go
func (c *Conversation) Done() (<-chan struct{}, error)
```

Done returns a channel that's closed when the duplex session ends. Only available when the conversation was opened with OpenDuplex\(\).

<a name="Conversation.EventBus"></a>
### func \(\*Conversation\) EventBus

```go
func (c *Conversation) EventBus() *events.EventBus
```

EventBus returns the conversation's event bus for observability.

Use this to subscribe to runtime events like tool calls, validations, and provider requests:

```
conv.EventBus().Subscribe(events.EventToolCallStarted, func(e *events.Event) {
    log.Printf("Tool call: %s", e.Data.(*events.ToolCallStartedData).ToolName)
})
```

For convenience methods, see the \[hooks\] package.

<a name="Conversation.Fork"></a>
### func \(\*Conversation\) Fork

```go
func (c *Conversation) Fork() *Conversation
```

Fork creates a copy of the current conversation state.

Use this to explore alternative conversation branches:

```
conv.Send(ctx, "I want to plan a trip")
conv.Send(ctx, "What cities should I visit?")

// Fork to explore different paths
branch := conv.Fork()

conv.Send(ctx, "Tell me about Tokyo")     // Original path
branch.Send(ctx, "Tell me about Kyoto")   // Branch path
```

The forked conversation is completely independent \- changes to one do not affect the other.

<a name="Conversation.GetVar"></a>
### func \(\*Conversation\) GetVar

```go
func (c *Conversation) GetVar(name string) (string, bool)
```

GetVar returns the current value of a template variable. Returns empty string and false if the variable is not set.

<a name="Conversation.ID"></a>
### func \(\*Conversation\) ID

```go
func (c *Conversation) ID() string
```

ID returns the conversation's unique identifier.

<a name="Conversation.Messages"></a>
### func \(\*Conversation\) Messages

```go
func (c *Conversation) Messages(ctx context.Context) []types.Message
```

Messages returns the conversation history.

The returned slice is a copy \- modifying it does not affect the conversation.

<a name="Conversation.OnTool"></a>
### func \(\*Conversation\) OnTool

```go
func (c *Conversation) OnTool(name string, handler ToolHandler)
```

OnTool registers a handler for a tool defined in the pack.

The tool name must match a tool defined in the pack's tools section. When the LLM calls the tool, your handler receives the parsed arguments and returns a result.

```
conv.OnTool("get_weather", func(args map[string]any) (any, error) {
    city := args["city"].(string)
    return weatherAPI.GetCurrent(city)
})
```

The handler's return value is automatically serialized to JSON and sent back to the LLM as the tool result.

<a name="Conversation.OnToolAsync"></a>
### func \(\*Conversation\) OnToolAsync

```go
func (c *Conversation) OnToolAsync(name string, checkFunc func(args map[string]any) sdktools.PendingResult, execFunc ToolHandler)
```

OnToolAsync registers a handler that may require approval before execution.

Use this for Human\-in\-the\-Loop \(HITL\) workflows where certain actions require human approval before proceeding:

```
conv.OnToolAsync("process_refund", func(args map[string]any) sdk.PendingResult {
    amount := args["amount"].(float64)
    if amount > 1000 {
        return sdk.PendingResult{
            Reason:  "high_value_refund",
            Message: fmt.Sprintf("Refund of $%.2f requires approval", amount),
        }
    }
    return sdk.PendingResult{} // Proceed immediately
}, func(args map[string]any) (any, error) {
    // Execute the actual refund
    return refundAPI.Process(args)
})
```

The first function checks if approval is needed, the second executes the action.

<a name="Conversation.OnToolCtx"></a>
### func \(\*Conversation\) OnToolCtx

```go
func (c *Conversation) OnToolCtx(name string, handler ToolHandlerCtx)
```

OnToolCtx registers a context\-aware handler for a tool.

Use this when your tool implementation needs the request context for cancellation, deadlines, or tracing:

```
conv.OnToolCtx("search_db", func(ctx context.Context, args map[string]any) (any, error) {
    return db.SearchWithContext(ctx, args["query"].(string))
})
```

<a name="Conversation.OnToolExecutor"></a>
### func \(\*Conversation\) OnToolExecutor

```go
func (c *Conversation) OnToolExecutor(name string, executor tools.Executor)
```

OnToolExecutor registers a custom executor for tools.

Use this when you need full control over tool execution or want to use a runtime executor directly:

```
executor := &MyCustomExecutor{}
conv.OnToolExecutor("custom_tool", executor)
```

The executor must implement the runtime/tools.Executor interface.

<a name="Conversation.OnToolHTTP"></a>
### func \(\*Conversation\) OnToolHTTP

```go
func (c *Conversation) OnToolHTTP(name string, config *sdktools.HTTPToolConfig)
```

OnToolHTTP registers a tool that makes HTTP requests.

This is a convenience method for tools that call external APIs:

```
conv.OnToolHTTP("create_ticket", sdktools.NewHTTPToolConfig(
    "https://api.tickets.example.com/tickets",
    sdktools.WithMethod("POST"),
    sdktools.WithHeader("Authorization", "Bearer "+apiKey),
    sdktools.WithTimeout(5000),
))
```

The tool arguments from the LLM are serialized to JSON and sent as the request body. The response is parsed and returned to the LLM.

<a name="Conversation.OnTools"></a>
### func \(\*Conversation\) OnTools

```go
func (c *Conversation) OnTools(handlers map[string]ToolHandler)
```

OnTools registers multiple tool handlers at once.

```
conv.OnTools(map[string]sdk.ToolHandler{
    "get_weather":   getWeatherHandler,
    "search_docs":   searchDocsHandler,
    "send_email":    sendEmailHandler,
})
```

<a name="Conversation.PendingTools"></a>
### func \(\*Conversation\) PendingTools

```go
func (c *Conversation) PendingTools() []*sdktools.PendingToolCall
```

PendingTools returns all pending tool calls awaiting approval.

<a name="Conversation.RejectTool"></a>
### func \(\*Conversation\) RejectTool

```go
func (c *Conversation) RejectTool(id, reason string) (*sdktools.ToolResolution, error)
```

RejectTool rejects a pending tool call.

Use this when the human reviewer decides not to approve the tool:

```
resp, _ := conv.RejectTool(pending.ID, "Not authorized for this amount")
```

<a name="Conversation.ResolveTool"></a>
### func \(\*Conversation\) ResolveTool

```go
func (c *Conversation) ResolveTool(id string) (*sdktools.ToolResolution, error)
```

ResolveTool approves and executes a pending tool call.

After calling Send\(\) and receiving pending tools in the response, use this to approve and execute them:

```
resp, _ := conv.Send(ctx, "Process refund for order #12345")
if len(resp.PendingTools()) > 0 {
    pending := resp.PendingTools()[0]
    // ... get approval ...
    result, _ := conv.ResolveTool(pending.ID)
    // Continue the conversation with the result
    resp, _ = conv.Continue(ctx)
}
```

<a name="Conversation.Response"></a>
### func \(\*Conversation\) Response

```go
func (c *Conversation) Response() (<-chan providers.StreamChunk, error)
```

Response returns the response channel for duplex streaming. Only available when the conversation was opened with OpenDuplex\(\).

<a name="Conversation.Send"></a>
### func \(\*Conversation\) Send

```go
func (c *Conversation) Send(ctx context.Context, message any, opts ...SendOption) (*Response, error)
```

Send sends a message to the LLM and returns the response.

The message can be a simple string or a \*types.Message for multimodal content. Variables are substituted into the system prompt template before sending.

Basic usage:

```
resp, err := conv.Send(ctx, "Hello!")
if err != nil {
    log.Fatal(err)
}
fmt.Println(resp.Text())
```

With message options:

```
resp, err := conv.Send(ctx, "What's in this image?",
    sdk.WithImageFile("/path/to/image.jpg"),
)
```

Send automatically:

- Substitutes variables into the system prompt
- Runs any registered validators
- Handles tool calls if tools are defined
- Persists state if a state store is configured

<a name="Conversation.SendChunk"></a>
### func \(\*Conversation\) SendChunk

```go
func (c *Conversation) SendChunk(ctx context.Context, chunk *providers.StreamChunk) error
```

SendChunk sends a streaming chunk in duplex mode. Only available when the conversation was opened with OpenDuplex\(\).

<a name="Conversation.SendText"></a>
### func \(\*Conversation\) SendText

```go
func (c *Conversation) SendText(ctx context.Context, text string) error
```

SendText sends text in duplex mode. Only available when the conversation was opened with OpenDuplex\(\).

<a name="Conversation.SessionError"></a>
### func \(\*Conversation\) SessionError

```go
func (c *Conversation) SessionError() error
```

SessionError returns any error from the duplex session. Only available when the conversation was opened with OpenDuplex\(\). Note: This is named SessionError to avoid conflict with the Error interface method.

<a name="Conversation.SetVar"></a>
### func \(\*Conversation\) SetVar

```go
func (c *Conversation) SetVar(name, value string)
```

SetVar sets a single template variable.

Variables are substituted into the system prompt template:

```
conv.SetVar("customer_name", "Alice")
// Template: "You are helping {{customer_name}}"
// Becomes: "You are helping Alice"
```

<a name="Conversation.SetVars"></a>
### func \(\*Conversation\) SetVars

```go
func (c *Conversation) SetVars(vars map[string]any)
```

SetVars sets multiple template variables at once.

```
conv.SetVars(map[string]any{
    "customer_name": "Alice",
    "customer_tier": "premium",
    "max_discount": 20,
})
```

<a name="Conversation.SetVarsFromEnv"></a>
### func \(\*Conversation\) SetVarsFromEnv

```go
func (c *Conversation) SetVarsFromEnv(prefix string)
```

SetVarsFromEnv sets variables from environment variables with a given prefix.

Environment variables matching the prefix are added as template variables with the prefix stripped and converted to lowercase:

```
// If PROMPTKIT_CUSTOMER_NAME=Alice is set:
conv.SetVarsFromEnv("PROMPTKIT_")
// Sets variable "customer_name" = "Alice"
```

<a name="Conversation.Stream"></a>
### func \(\*Conversation\) Stream

```go
func (c *Conversation) Stream(ctx context.Context, message any, opts ...SendOption) <-chan StreamChunk
```

Stream sends a message and returns a channel of response chunks.

Use this for real\-time streaming of LLM responses:

```
for chunk := range conv.Stream(ctx, "Tell me a story") {
    if chunk.Error != nil {
        log.Printf("Error: %v", chunk.Error)
        break
    }
    fmt.Print(chunk.Text)
}
```

The channel is closed when the response is complete or an error occurs. The final chunk \(Type == ChunkDone\) contains the complete Response.

<a name="Conversation.StreamRaw"></a>
### func \(\*Conversation\) StreamRaw

```go
func (c *Conversation) StreamRaw(ctx context.Context, message any) (<-chan streamPkg.Chunk, error)
```

StreamRaw returns a channel of streaming chunks for use with the stream package. This is a lower\-level API that returns stream.Chunk types.

Most users should use [Conversation.Stream](<#Conversation.Stream>) instead. StreamRaw is useful when working with \[stream.Process\] or \[stream.CollectText\].

```
err := stream.Process(ctx, conv, "Hello", func(chunk stream.Chunk) error {
    fmt.Print(chunk.Text)
    return nil
})
```

<a name="Conversation.ToolRegistry"></a>
### func \(\*Conversation\) ToolRegistry

```go
func (c *Conversation) ToolRegistry() *tools.Registry
```

ToolRegistry returns the underlying tool registry.

This is a power\-user method for direct registry access. Tool descriptors are loaded from the pack; this allows inspecting them or registering custom executors.

```
registry := conv.ToolRegistry().(*tools.Registry)
for _, desc := range registry.Descriptors() {
    fmt.Printf("Tool: %s\n", desc.Name)
}
```

<a name="Conversation.TriggerStart"></a>
### func \(\*Conversation\) TriggerStart

```go
func (c *Conversation) TriggerStart(ctx context.Context, message string) error
```

TriggerStart sends a text message to make the model initiate the conversation. Use this in ASM mode when you want the model to speak first \(e.g., introducing itself\). Only available when the conversation was opened with OpenDuplex\(\).

Example:

```
conv, _ := sdk.OpenDuplex("./assistant.pack.json", "interviewer", ...)
// Start processing responses first
go processResponses(conv.Response())
// Trigger the model to begin
conv.TriggerStart(ctx, "Please introduce yourself and begin the interview.")
```

<a name="MCPServerBuilder"></a>
## type MCPServerBuilder

MCPServerBuilder provides a fluent interface for configuring MCP servers.

```go
type MCPServerBuilder struct {
    // contains filtered or unexported fields
}
```

<a name="NewMCPServer"></a>
### func NewMCPServer

```go
func NewMCPServer(name, command string, args ...string) *MCPServerBuilder
```

NewMCPServer creates a new MCP server configuration builder.

```
server := sdk.NewMCPServer("github", "npx", "@modelcontextprotocol/server-github").
    WithEnv("GITHUB_TOKEN", os.Getenv("GITHUB_TOKEN"))

conv, _ := sdk.Open("./assistant.pack.json", "assistant",
    sdk.WithMCPServer(server),
)
```

<a name="MCPServerBuilder.Build"></a>
### func \(\*MCPServerBuilder\) Build

```go
func (b *MCPServerBuilder) Build() mcp.ServerConfig
```

Build returns the configured server config.

<a name="MCPServerBuilder.WithArgs"></a>
### func \(\*MCPServerBuilder\) WithArgs

```go
func (b *MCPServerBuilder) WithArgs(args ...string) *MCPServerBuilder
```

WithArgs appends additional arguments to the MCP server command.

<a name="MCPServerBuilder.WithEnv"></a>
### func \(\*MCPServerBuilder\) WithEnv

```go
func (b *MCPServerBuilder) WithEnv(key, value string) *MCPServerBuilder
```

WithEnv adds an environment variable to the MCP server.

<a name="Option"></a>
## type Option

Option configures a Conversation.

```go
type Option func(*config) error
```

<a name="WithAPIKey"></a>
### func WithAPIKey

```go
func WithAPIKey(key string) Option
```

WithAPIKey provides an explicit API key instead of reading from environment.

```
conv, _ := sdk.Open("./chat.pack.json", "assistant",
    sdk.WithAPIKey(os.Getenv("MY_CUSTOM_KEY")),
)
```

<a name="WithConversationID"></a>
### func WithConversationID

```go
func WithConversationID(id string) Option
```

WithConversationID sets the conversation identifier.

If not set, a unique ID is auto\-generated. Set this when you want to use a specific ID for state persistence or tracking.

```
conv, _ := sdk.Open("./chat.pack.json", "assistant",
    sdk.WithStateStore(store),
    sdk.WithConversationID("user-123-session-456"),
)
```

<a name="WithDisabledValidators"></a>
### func WithDisabledValidators

```go
func WithDisabledValidators(names ...string) Option
```

WithDisabledValidators disables specific validators by name.

```
conv, _ := sdk.Open("./chat.pack.json", "assistant",
    sdk.WithDisabledValidators("max_length", "banned_words"),
)
```

<a name="WithEventBus"></a>
### func WithEventBus

```go
func WithEventBus(bus *events.EventBus) Option
```

WithEventBus provides a shared event bus for observability.

When set, the conversation emits events to this bus. Use this to share an event bus across multiple conversations for centralized logging, metrics, or debugging.

```
bus := events.NewEventBus()
bus.SubscribeAll(myMetricsCollector)

conv1, _ := sdk.Open("./chat.pack.json", "assistant", sdk.WithEventBus(bus))
conv2, _ := sdk.Open("./chat.pack.json", "assistant", sdk.WithEventBus(bus))
```

<a name="WithMCP"></a>
### func WithMCP

```go
func WithMCP(name, command string, args ...string) Option
```

WithMCP adds an MCP \(Model Context Protocol\) server for tool execution.

MCP servers provide external tools that can be called by the LLM. The server is started automatically when the conversation opens and stopped when the conversation is closed.

Basic usage:

```
conv, _ := sdk.Open("./assistant.pack.json", "assistant",
    sdk.WithMCP("filesystem", "npx", "@modelcontextprotocol/server-filesystem", "/path"),
)
```

With environment variables:

```
conv, _ := sdk.Open("./assistant.pack.json", "assistant",
    sdk.WithMCP("github", "npx", "@modelcontextprotocol/server-github").
        WithEnv("GITHUB_TOKEN", os.Getenv("GITHUB_TOKEN")),
)
```

Multiple servers:

```
conv, _ := sdk.Open("./assistant.pack.json", "assistant",
    sdk.WithMCP("filesystem", "npx", "@modelcontextprotocol/server-filesystem", "/path"),
    sdk.WithMCP("memory", "npx", "@modelcontextprotocol/server-memory"),
)
```

<a name="WithMCPServer"></a>
### func WithMCPServer

```go
func WithMCPServer(builder *MCPServerBuilder) Option
```

WithMCPServer adds a pre\-configured MCP server.

```
server := sdk.NewMCPServer("github", "npx", "@modelcontextprotocol/server-github").
    WithEnv("GITHUB_TOKEN", os.Getenv("GITHUB_TOKEN"))

conv, _ := sdk.Open("./assistant.pack.json", "assistant",
    sdk.WithMCPServer(server),
)
```

<a name="WithModel"></a>
### func WithModel

```go
func WithModel(model string) Option
```

WithModel overrides the default model specified in the pack.

```
conv, _ := sdk.Open("./chat.pack.json", "assistant",
    sdk.WithModel("gpt-4o"),
)
```

<a name="WithProvider"></a>
### func WithProvider

```go
func WithProvider(p providers.Provider) Option
```

WithProvider uses a custom provider instance.

This bypasses auto\-detection and uses the provided provider directly. Use this for custom provider implementations or when you need full control over provider configuration.

```
provider := openai.NewProvider(openai.Config{...})
conv, _ := sdk.Open("./chat.pack.json", "assistant",
    sdk.WithProvider(provider),
)
```

<a name="WithRelevanceTruncation"></a>
### func WithRelevanceTruncation

```go
func WithRelevanceTruncation(cfg *RelevanceConfig) Option
```

WithRelevanceTruncation configures embedding\-based relevance truncation.

This automatically sets the truncation strategy to "relevance" and configures the embedding provider for semantic similarity scoring.

Example with OpenAI embeddings:

```
embProvider, _ := openai.NewEmbeddingProvider()
conv, _ := sdk.Open("./chat.pack.json", "assistant",
    sdk.WithTokenBudget(8000),
    sdk.WithRelevanceTruncation(&sdk.RelevanceConfig{
        EmbeddingProvider: embProvider,
        MinRecentMessages: 3,
        SimilarityThreshold: 0.3,
    }),
)
```

Example with Gemini embeddings:

```
embProvider, _ := gemini.NewEmbeddingProvider()
conv, _ := sdk.Open("./chat.pack.json", "assistant",
    sdk.WithTokenBudget(8000),
    sdk.WithRelevanceTruncation(&sdk.RelevanceConfig{
        EmbeddingProvider: embProvider,
    }),
)
```

<a name="WithSkipSchemaValidation"></a>
### func WithSkipSchemaValidation

```go
func WithSkipSchemaValidation() Option
```

WithSkipSchemaValidation disables JSON schema validation during pack loading.

By default, packs are validated against the PromptPack JSON schema to ensure they are well\-formed. Use this option to skip validation, for example when loading legacy packs or during development.

```
conv, _ := sdk.Open("./legacy.pack.json", "assistant",
    sdk.WithSkipSchemaValidation(),
)
```

<a name="WithStateStore"></a>
### func WithStateStore

```go
func WithStateStore(store statestore.Store) Option
```

WithStateStore configures persistent state storage.

When configured, conversation state \(messages, metadata\) is automatically persisted after each turn and can be resumed later via [Resume](<#Resume>).

```
store := statestore.NewRedisStore("redis://localhost:6379")
conv, _ := sdk.Open("./chat.pack.json", "assistant",
    sdk.WithStateStore(store),
)
```

<a name="WithStreamingConfig"></a>
### func WithStreamingConfig

```go
func WithStreamingConfig(streamingConfig *providers.StreamingInputConfig) Option
```

WithStreamingConfig configures streaming for duplex mode. When set, enables ASM \(Audio Streaming Model\) mode with continuous bidirectional streaming. When nil \(default\), uses VAD \(Voice Activity Detection\) mode with turn\-based streaming.

ASM mode is for models with native bidirectional audio support \(e.g., gemini\-2.0\-flash\-exp\). VAD mode is for standard text\-based models with audio transcription.

Example for ASM mode:

```
conv, _ := sdk.OpenDuplex("./assistant.pack.json", "voice-chat",
    sdk.WithStreamingConfig(&providers.StreamingInputConfig{
        Type:       types.ContentTypeAudio,
        SampleRate: 16000,
        Channels:   1,
    }),
)
```

<a name="WithStrictValidation"></a>
### func WithStrictValidation

```go
func WithStrictValidation() Option
```

WithStrictValidation makes all validators fail on violation.

Normally, validators respect their fail\_on\_violation setting from the pack. With strict validation, all validators will cause errors on failure.

```
conv, _ := sdk.Open("./chat.pack.json", "assistant",
    sdk.WithStrictValidation(),
)
```

<a name="WithTTS"></a>
### func WithTTS

```go
func WithTTS(service tts.Service) Option
```

WithTTS configures text\-to\-speech for the Pipeline.

TTS is applied via Pipeline middleware during streaming responses.

```
conv, _ := sdk.Open("./assistant.pack.json", "voice",
    sdk.WithTTS(tts.NewOpenAI(os.Getenv("OPENAI_API_KEY"))),
)
```

<a name="WithTokenBudget"></a>
### func WithTokenBudget

```go
func WithTokenBudget(tokens int) Option
```

WithTokenBudget sets the maximum tokens for context \(prompt \+ history\).

When the conversation history exceeds this budget, older messages are truncated according to the truncation strategy.

```
conv, _ := sdk.Open("./chat.pack.json", "assistant",
    sdk.WithTokenBudget(8000),
)
```

<a name="WithToolRegistry"></a>
### func WithToolRegistry

```go
func WithToolRegistry(registry *tools.Registry) Option
```

WithToolRegistry provides a pre\-configured tool registry.

This is a power\-user option for scenarios requiring direct registry access. Tool descriptors are still loaded from the pack; this allows providing custom executors or middleware.

```
registry := tools.NewRegistry()
registry.RegisterExecutor(&myCustomExecutor{})
conv, _ := sdk.Open("./chat.pack.json", "assistant",
    sdk.WithToolRegistry(registry),
)
```

<a name="WithTruncation"></a>
### func WithTruncation

```go
func WithTruncation(strategy string) Option
```

WithTruncation sets the truncation strategy for context management.

Strategies:

- "sliding": Remove oldest messages first \(default\)

- "summarize": Summarize old messages before removing

- "relevance": Remove least relevant messages based on embedding similarity
  
  conv, \_ := sdk.Open\("./chat.pack.json", "assistant", sdk.WithTokenBudget\(8000\), sdk.WithTruncation\("summarize"\), \)

<a name="WithTurnDetector"></a>
### func WithTurnDetector

```go
func WithTurnDetector(detector audio.TurnDetector) Option
```

WithTurnDetector configures turn detection for the Pipeline.

Turn detectors determine when a user has finished speaking in audio sessions.

```
conv, _ := sdk.Open("./assistant.pack.json", "voice",
    sdk.WithTurnDetector(audio.NewSilenceDetector(500 * time.Millisecond)),
)
```

<a name="WithVADMode"></a>
### func WithVADMode

```go
func WithVADMode(sttService stt.Service, ttsService tts.Service, cfg *VADModeConfig) Option
```

WithVADMode configures VAD mode for voice conversations with standard text\-based LLMs. VAD mode processes audio through a pipeline: Audio → VAD → STT → LLM → TTS → Audio

This is an alternative to ASM mode \(WithStreamingConfig\) for providers without native audio streaming support.

Example:

```
sttService := stt.NewOpenAI(os.Getenv("OPENAI_API_KEY"))
ttsService := tts.NewOpenAI(os.Getenv("OPENAI_API_KEY"))

conv, _ := sdk.OpenDuplex("./assistant.pack.json", "voice-chat",
    sdk.WithProvider(openai.NewProvider(openai.Config{...})),
    sdk.WithVADMode(sttService, ttsService, nil), // nil uses defaults
)
```

With custom config:

```
conv, _ := sdk.OpenDuplex("./assistant.pack.json", "voice-chat",
    sdk.WithProvider(openai.NewProvider(openai.Config{...})),
    sdk.WithVADMode(sttService, ttsService, &sdk.VADModeConfig{
        SilenceDuration: 500 * time.Millisecond,
        Voice:           "nova",
    }),
)
```

<a name="WithValidationMode"></a>
### func WithValidationMode

```go
func WithValidationMode(mode ValidationMode) Option
```

WithValidationMode sets how validation failures are handled.

```
// Suppress validation errors (useful for testing)
conv, _ := sdk.Open("./chat.pack.json", "assistant",
    sdk.WithValidationMode(sdk.ValidationModeWarn),
)
```

<a name="WithVariableProvider"></a>
### func WithVariableProvider

```go
func WithVariableProvider(p variables.Provider) Option
```

WithVariableProvider adds a variable provider for dynamic variable resolution.

Variables are resolved before each Send\(\) and merged with static variables. Later providers in the chain override earlier ones with the same key.

```
conv, _ := sdk.Open("./assistant.pack.json", "support",
    sdk.WithVariableProvider(variables.Time()),
    sdk.WithVariableProvider(variables.State()),
)
```

<a name="WithVariables"></a>
### func WithVariables

```go
func WithVariables(vars map[string]string) Option
```

WithVariables sets initial variables for template substitution.

These variables are available immediately when the conversation opens, before any messages are sent. Use this for variables that must be set before the first LLM call \(e.g., in streaming/ASM mode\).

Variables set here override prompt defaults but can be further modified via conv.SetVar\(\) for subsequent messages.

```
conv, _ := sdk.Open("./assistant.pack.json", "assistant",
    sdk.WithVariables(map[string]string{
        "user_name": "Alice",
        "language": "en",
    }),
)
```

<a name="PackError"></a>
## type PackError

PackError represents an error loading or parsing a pack file.

```go
type PackError struct {
    // Path is the pack file path.
    Path string

    // Cause is the underlying error.
    Cause error
}
```

<a name="PackError.Error"></a>
### func \(\*PackError\) Error

```go
func (e *PackError) Error() string
```

Error implements the error interface.

<a name="PackError.Unwrap"></a>
### func \(\*PackError\) Unwrap

```go
func (e *PackError) Unwrap() error
```

Unwrap returns the underlying error.

<a name="PendingTool"></a>
## type PendingTool

PendingTool represents a tool call that requires external approval.

```go
type PendingTool struct {
    // Unique identifier for this pending call
    ID  string

    // Tool name
    Name string

    // Arguments passed to the tool
    Arguments map[string]any

    // Reason the tool requires approval
    Reason string

    // Human-readable message about why approval is needed
    Message string
}
```

<a name="ProviderError"></a>
## type ProviderError

ProviderError represents an error from the LLM provider.

```go
type ProviderError struct {
    // Provider name (e.g., "openai", "anthropic").
    Provider string

    // StatusCode is the HTTP status code if available.
    StatusCode int

    // Message is the error message from the provider.
    Message string

    // Cause is the underlying error.
    Cause error
}
```

<a name="ProviderError.Error"></a>
### func \(\*ProviderError\) Error

```go
func (e *ProviderError) Error() string
```

Error implements the error interface.

<a name="ProviderError.Unwrap"></a>
### func \(\*ProviderError\) Unwrap

```go
func (e *ProviderError) Unwrap() error
```

Unwrap returns the underlying error.

<a name="RelevanceConfig"></a>
## type RelevanceConfig

RelevanceConfig configures embedding\-based relevance truncation. Used when truncation strategy is "relevance".

```go
type RelevanceConfig struct {
    // EmbeddingProvider generates embeddings for similarity scoring.
    // Required for relevance-based truncation.
    EmbeddingProvider providers.EmbeddingProvider

    // MinRecentMessages always keeps the N most recent messages regardless of relevance.
    // Default: 3
    MinRecentMessages int

    // AlwaysKeepSystemRole keeps all system role messages regardless of score.
    // Default: true
    AlwaysKeepSystemRole bool

    // SimilarityThreshold is the minimum score (0.0-1.0) to consider a message relevant.
    // Messages below this threshold are dropped first. Default: 0.0 (no threshold)
    SimilarityThreshold float64

    // QuerySource determines what text to compare messages against.
    // Values: "last_user" (default), "last_n", "custom"
    QuerySource string

    // LastNCount is the number of messages to use when QuerySource is "last_n".
    // Default: 3
    LastNCount int

    // CustomQuery is the query text when QuerySource is "custom".
    CustomQuery string
}
```

<a name="Response"></a>
## type Response

Response represents the result of a conversation turn.

Response wraps the assistant's message with convenience methods and additional metadata like timing and validation results.

Basic usage:

```
resp, _ := conv.Send(ctx, "Hello!")
fmt.Println(resp.Text())           // Text content
fmt.Println(resp.TokensUsed())     // Total tokens
fmt.Println(resp.Cost())           // Total cost in USD
```

For multimodal responses:

```
if resp.HasMedia() {
    for _, part := range resp.Parts() {
        if part.Media != nil {
            fmt.Printf("Media: %s\n", part.Media.URL)
        }
    }
}
```

```go
type Response struct {
    // contains filtered or unexported fields
}
```

<a name="Response.Cost"></a>
### func \(\*Response\) Cost

```go
func (r *Response) Cost() float64
```

Cost returns the total cost in USD for this response.

<a name="Response.Duration"></a>
### func \(\*Response\) Duration

```go
func (r *Response) Duration() time.Duration
```

Duration returns how long the request took.

<a name="Response.HasMedia"></a>
### func \(\*Response\) HasMedia

```go
func (r *Response) HasMedia() bool
```

HasMedia returns true if the response contains any media content.

<a name="Response.HasToolCalls"></a>
### func \(\*Response\) HasToolCalls

```go
func (r *Response) HasToolCalls() bool
```

HasToolCalls returns true if the response contains tool calls.

<a name="Response.InputTokens"></a>
### func \(\*Response\) InputTokens

```go
func (r *Response) InputTokens() int
```

InputTokens returns the number of input \(prompt\) tokens used.

<a name="Response.Message"></a>
### func \(\*Response\) Message

```go
func (r *Response) Message() *types.Message
```

Message returns the underlying runtime Message.

Use this when you need direct access to the message structure, such as for serialization or passing to other runtime components.

<a name="Response.OutputTokens"></a>
### func \(\*Response\) OutputTokens

```go
func (r *Response) OutputTokens() int
```

OutputTokens returns the number of output \(completion\) tokens used.

<a name="Response.Parts"></a>
### func \(\*Response\) Parts

```go
func (r *Response) Parts() []types.ContentPart
```

Parts returns all content parts in the response.

Use this for multimodal responses that may contain text, images, audio, or other content types.

<a name="Response.PendingTools"></a>
### func \(\*Response\) PendingTools

```go
func (r *Response) PendingTools() []PendingTool
```

PendingTools returns tools that are awaiting external approval.

This is used for Human\-in\-the\-Loop \(HITL\) workflows where certain tools require approval before execution.

<a name="Response.Text"></a>
### func \(\*Response\) Text

```go
func (r *Response) Text() string
```

Text returns the text content of the response.

This is a convenience method that extracts all text parts and joins them. For responses with only text content, this returns the full response. For multimodal responses, use [Response.Parts](<#Response.Parts>) to access all content.

<a name="Response.TokensUsed"></a>
### func \(\*Response\) TokensUsed

```go
func (r *Response) TokensUsed() int
```

TokensUsed returns the total number of tokens used \(input \+ output\).

<a name="Response.ToolCalls"></a>
### func \(\*Response\) ToolCalls

```go
func (r *Response) ToolCalls() []types.MessageToolCall
```

ToolCalls returns the tool calls made during this turn.

Tool calls are requests from the LLM to execute functions. If you have registered handlers via [Conversation.OnTool](<#Conversation.OnTool>), they will be executed automatically and the results sent back to the LLM.

<a name="Response.Validations"></a>
### func \(\*Response\) Validations

```go
func (r *Response) Validations() []types.ValidationResult
```

Validations returns the results of all validators that ran.

Validators are defined in the pack and run automatically on responses. Check this to see which validators passed or failed.

<a name="SendOption"></a>
## type SendOption

SendOption configures a single Send call.

```go
type SendOption func(*sendConfig) error
```

<a name="WithAudioFile"></a>
### func WithAudioFile

```go
func WithAudioFile(path string) SendOption
```

WithAudioFile attaches audio from a file path.

```
resp, _ := conv.Send(ctx, "Transcribe this audio",
    sdk.WithAudioFile("/path/to/audio.mp3"),
)
```

<a name="WithFile"></a>
### func WithFile

```go
func WithFile(name string, data []byte) SendOption
```

WithFile attaches a file with the given name and content.

```
resp, _ := conv.Send(ctx, "Analyze this data",
    sdk.WithFile("data.csv", csvBytes),
)
```

<a name="WithImageData"></a>
### func WithImageData

```go
func WithImageData(data []byte, mimeType string, detail ...*string) SendOption
```

WithImageData attaches an image from raw bytes.

```
resp, _ := conv.Send(ctx, "What's in this image?",
    sdk.WithImageData(imageBytes, "image/png"),
)
```

<a name="WithImageFile"></a>
### func WithImageFile

```go
func WithImageFile(path string, detail ...*string) SendOption
```

WithImageFile attaches an image from a file path.

```
resp, _ := conv.Send(ctx, "What's in this image?",
    sdk.WithImageFile("/path/to/image.jpg"),
)
```

<a name="WithImageURL"></a>
### func WithImageURL

```go
func WithImageURL(url string, detail ...*string) SendOption
```

WithImageURL attaches an image from a URL.

```
resp, _ := conv.Send(ctx, "What's in this image?",
    sdk.WithImageURL("https://example.com/photo.jpg"),
)
```

<a name="SessionMode"></a>
## type SessionMode

SessionMode represents the conversation's session mode.

```go
type SessionMode int
```

<a name="UnaryMode"></a>

```go
const (
    // UnaryMode for request/response conversations.
    UnaryMode SessionMode = iota
    // DuplexMode for bidirectional streaming conversations.
    DuplexMode
)
```

<a name="StreamChunk"></a>
## type StreamChunk

StreamChunk represents a single chunk in a streaming response.

```go
type StreamChunk struct {
    // Type of this chunk
    Type ChunkType

    // Text content (for ChunkText type)
    Text string

    // Tool call (for ChunkToolCall type)
    ToolCall *types.MessageToolCall

    // Media content (for ChunkMedia type)
    Media *types.MediaContent

    // Complete response (for ChunkDone type)
    Message *Response

    // Error (if any occurred)
    Error error
}
```

<a name="ToolError"></a>
## type ToolError

ToolError represents an error executing a tool.

```go
type ToolError struct {
    // ToolName is the name of the tool that failed.
    ToolName string

    // Cause is the underlying error from the tool handler.
    Cause error
}
```

<a name="ToolError.Error"></a>
### func \(\*ToolError\) Error

```go
func (e *ToolError) Error() string
```

Error implements the error interface.

<a name="ToolError.Unwrap"></a>
### func \(\*ToolError\) Unwrap

```go
func (e *ToolError) Unwrap() error
```

Unwrap returns the underlying error.

<a name="ToolHandler"></a>
## type ToolHandler

ToolHandler is a function that executes a tool call. It receives the parsed arguments from the LLM and returns a result.

The args map contains the arguments as specified in the tool's schema. The return value should be JSON\-serializable.

```
conv.OnTool("get_weather", func(args map[string]any) (any, error) {
    city := args["city"].(string)
    return weatherAPI.GetCurrent(city)
})
```

```go
type ToolHandler func(args map[string]any) (any, error)
```

<a name="ToolHandlerCtx"></a>
## type ToolHandlerCtx

ToolHandlerCtx is like [ToolHandler](<#ToolHandler>) but receives a context. Use this when your tool implementation needs context for cancellation or deadlines.

```
conv.OnToolCtx("search_db", func(ctx context.Context, args map[string]any) (any, error) {
    return db.SearchWithContext(ctx, args["query"].(string))
})
```

```go
type ToolHandlerCtx func(ctx context.Context, args map[string]any) (any, error)
```

<a name="VADModeConfig"></a>
## type VADModeConfig

VADModeConfig configures VAD \(Voice Activity Detection\) mode for voice conversations. In VAD mode, the pipeline processes audio through: AudioTurnStage → STTStage → ProviderStage → TTSStage

This enables voice conversations using standard text\-based LLMs.

```go
type VADModeConfig struct {
    // SilenceDuration is how long silence must persist to trigger turn complete.
    // Default: 800ms
    SilenceDuration time.Duration

    // MinSpeechDuration is minimum speech before turn can complete.
    // Default: 200ms
    MinSpeechDuration time.Duration

    // MaxTurnDuration is maximum turn length before forcing completion.
    // Default: 30s
    MaxTurnDuration time.Duration

    // SampleRate is the audio sample rate.
    // Default: 16000
    SampleRate int

    // Language is the language hint for STT (e.g., "en", "es").
    // Default: "en"
    Language string

    // Voice is the TTS voice to use.
    // Default: "alloy"
    Voice string

    // Speed is the TTS speech rate (0.5-2.0).
    // Default: 1.0
    Speed float64
}
```

<a name="DefaultVADModeConfig"></a>
### func DefaultVADModeConfig

```go
func DefaultVADModeConfig() *VADModeConfig
```

DefaultVADModeConfig returns sensible defaults for VAD mode.

<a name="ValidationError"></a>
## type ValidationError

ValidationError represents a validation failure.

```go
type ValidationError struct {
    // ValidatorType is the type of validator that failed (e.g., "banned_words").
    ValidatorType string

    // Message describes what validation rule was violated.
    Message string

    // Details contains validator-specific information about the failure.
    Details map[string]any
}
```

<a name="AsValidationError"></a>
### func AsValidationError

```go
func AsValidationError(err error) (*ValidationError, bool)
```

AsValidationError checks if an error is a ValidationError and returns it.

```
resp, err := conv.Send(ctx, message)
if err != nil {
    if vErr, ok := sdk.AsValidationError(err); ok {
        fmt.Printf("Validation failed: %s\n", vErr.ValidatorType)
    }
}
```

<a name="ValidationError.Error"></a>
### func \(\*ValidationError\) Error

```go
func (e *ValidationError) Error() string
```

Error implements the error interface.

<a name="ValidationMode"></a>
## type ValidationMode

ValidationMode controls how validation failures are handled.

```go
type ValidationMode int
```

<a name="ValidationModeError"></a>

```go
const (
    // ValidationModeError causes validation failures to return errors (default).
    ValidationModeError ValidationMode = iota

    // ValidationModeWarn logs validation failures but doesn't return errors.
    ValidationModeWarn

    // ValidationModeDisabled skips validation entirely.
    ValidationModeDisabled
)
```

Generated by [gomarkdoc](<https://github.com/princjef/gomarkdoc>)
